# ğŸ¤– Assistente Virtual Controlado por Gestos

Sistema de assistente virtual que combina **detecÃ§Ã£o de gestos manuais via webcam** com **reconhecimento de voz offline (Whisper)** para controle por comandos naturais.

## âœ¨ Funcionalidades

### ğŸ¤– VersÃ£o com IA (`assistente_ia.py`) - Recomendado
- ğŸ–ï¸ **DetecÃ§Ã£o de MÃ£os**: Rastreamento em tempo real usando MediaPipe
- ğŸ¯ **Reconhecimento de Gestos**: Identifica gestos especÃ­ficos (mÃ£o aberta, punho, dedos levantados)
- ğŸ¤ **Reconhecimento de Voz**: TranscriÃ§Ã£o offline em portuguÃªs usando Whisper
- ğŸ§  **IA Conversacional**: Respostas inteligentes (Ollama/OpenAI/Groq)
- ğŸ”Š **SÃ­ntese de Voz (TTS)**: Assistente fala as respostas
- âš™ï¸ **Comandos do Sistema**: Controle do computador por voz
- ğŸ”„ **MÃ¡quina de Estados**: Sistema inteligente que responde a gestos
- ğŸ’¬ **Interface Visual**: Feedback em tempo real na tela

### ğŸ® VersÃ£o BÃ¡sica (`assistente_gestos.py`)
- Todas as funcionalidades acima, exceto IA conversacional e TTS
- Ideal para testar o sistema sem dependÃªncias de IA

## ğŸ® Gestos DisponÃ­veis

| Gesto | AÃ§Ã£o |
|-------|------|
| âœ‹ MÃ£o aberta (5 dedos) | Ativa o assistente |
| â˜ï¸ Um dedo (indicador) | Inicia gravaÃ§Ã£o de voz (5 segundos) |
| ğŸ‘Š Punho fechado | Desativa o assistente |
| âœŒï¸ Dois dedos (V) | Cancela operaÃ§Ã£o atual |

## ğŸš€ Como Usar

### 1. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Instalar FFmpeg (NecessÃ¡rio para Whisper)

**Windows:** Veja instruÃ§Ãµes detalhadas em [INSTALAR_FFMPEG.md](INSTALAR_FFMPEG.md)

**RÃ¡pido (com Chocolatey):**
```powershell
choco install ffmpeg
```

**Linux:**
```bash
sudo apt install ffmpeg  # Ubuntu/Debian
```

**macOS:**
```bash
brew install ffmpeg
```

### 3. Configurar IA (Opcional - apenas para `assistente_ia.py`)

**OpÃ§Ã£o 1: Ollama (Recomendado - Gratuito e Offline)**
```bash
# Baixar e instalar: https://ollama.com/download
# Depois, baixar um modelo:
ollama pull llama3.2:3b
```

**OpÃ§Ã£o 2: OpenAI (Pago)**
```bash
export OPENAI_API_KEY='sua-chave-aqui'
```

**OpÃ§Ã£o 3: Groq (Gratuito com limites)**
```bash
export GROQ_API_KEY='sua-chave-aqui'
```

### 4. Executar o Assistente

**VersÃ£o com IA (recomendado):**
```bash
python assistente_ia.py
```

**VersÃ£o bÃ¡sica (sem IA):**
```bash
python assistente_gestos.py
```

### 5. Interagir

1. Mostre a **mÃ£o aberta** para ativar (status fica verde)
2. Mostre **um dedo** para gravar um comando de voz
3. **Fale seu comando** durante 5 segundos
4. A transcriÃ§Ã£o aparecerÃ¡ na tela
5. Feche o **punho** para desativar

Pressione **ESC** para sair.

## ğŸ“ Estrutura do Projeto

```
hand_tracking/
â”œâ”€â”€ assistente_ia.py          # â­ Assistente com IA conversacional e TTS
â”œâ”€â”€ assistente_gestos.py      # Assistente bÃ¡sico (sem IA)
â”œâ”€â”€ ai_assistant.py           # MÃ³dulo de IA (Ollama/OpenAI/Groq)
â”œâ”€â”€ command_executor.py       # Executor de comandos do sistema
â”œâ”€â”€ gesture_recognition.py    # MÃ³dulo de reconhecimento de gestos
â”œâ”€â”€ voice_recognition.py      # MÃ³dulo de reconhecimento de voz
â”œâ”€â”€ detect_webcam.py          # Script original de detecÃ§Ã£o de mÃ£os
â”œâ”€â”€ GUIA_USO.md              # ğŸ“š Guia completo de uso
â”œâ”€â”€ INSTALAR_FFMPEG.md       # Tutorial de instalaÃ§Ã£o do FFmpeg
â”œâ”€â”€ CLAUDE.md                # DocumentaÃ§Ã£o para Claude Code
â””â”€â”€ README.md                # Este arquivo
```

## ğŸ› ï¸ Tecnologias

- **Python 3.9+**
- **MediaPipe** - DetecÃ§Ã£o de mÃ£os e landmarks
- **OpenCV** - Captura e processamento de vÃ­deo
- **OpenAI Whisper** - Reconhecimento de voz offline
- **Ollama / OpenAI / Groq** - IA conversacional
- **pyttsx3** - SÃ­ntese de voz (TTS)
- **SoundDevice** - Captura de Ã¡udio do microfone
- **NumPy & SciPy** - Processamento de dados

## ğŸ“‹ Requisitos

- Python 3.9 ou superior
- Webcam funcional
- Microfone funcional
- ~500MB de espaÃ§o para modelo Whisper (baixado automaticamente)

## ğŸ¯ PrÃ³ximos Passos

### âœ… Implementado
- [x] IA conversacional com mÃºltiplos providers (Ollama, OpenAI, Groq)
- [x] Comandos customizados do sistema (abrir apps, volume, pesquisa)
- [x] SÃ­ntese de voz (TTS) para respostas da IA
- [x] Interface visual aprimorada com status e feedback
- [x] DocumentaÃ§Ã£o completa (GUIA_USO.md)

### ğŸš€ Melhorias Futuras
- [ ] Suporte a mÃºltiplas mÃ£os simultÃ¢neas
- [ ] Gestos personalizÃ¡veis pelo usuÃ¡rio
- [ ] HistÃ³rico de conversas persistente
- [ ] IntegraÃ§Ã£o com APIs externas (clima, notÃ­cias)
- [ ] Controle de aplicativos especÃ­ficos (Spotify, PowerPoint)
- [ ] Reconhecimento facial para perfis de usuÃ¡rio
- [ ] Dashboard web para configuraÃ§Ã£o
- [ ] Suporte a comandos via atalhos de teclado

## ğŸ“ Notas

- O modelo Whisper Ã© baixado automaticamente na primeira execuÃ§Ã£o (~150MB)
- Modelos ficam em cache: `~/.cache/whisper/`
- Arquivos de Ã¡udio temporÃ¡rios ficam em: `temp/`
- Idioma de transcriÃ§Ã£o configurado para portuguÃªs brasileiro

## ğŸ¤ Contribuindo

Este Ã© um projeto pessoal, mas sugestÃµes sÃ£o bem-vindas!

## ğŸ“„ LicenÃ§a

Projeto pessoal de estudos.
