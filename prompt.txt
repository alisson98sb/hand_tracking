Quero que vocÃª atue como um desenvolvedor sÃªnior de visÃ£o computacional e integraÃ§Ã£o de IA multimodal.

Meu objetivo Ã© desenvolver uma aplicaÃ§Ã£o chamada **"Assistente Virtual Controlado por Gestos"**, que combina **detecÃ§Ã£o de gestos manuais via webcam** com **reconhecimento de voz offline (Whisper local)** e **respostas inteligentes geradas por uma IA conversacional**.

A base tÃ©cnica serÃ¡ em **Python**, e o sistema deve conter os seguintes mÃ³dulos:

---

## ğŸ“ Estado Atual do Projeto

### âœ… Implementado em `detect_webcam.py`:
- DetecÃ§Ã£o de mÃ£os usando **Mediapipe** e **OpenCV** (resoluÃ§Ã£o 1280x720)
- FunÃ§Ã£o `find_coord_hand()`: detecta mÃ£os e extrai coordenadas dos 21 landmarks
- FunÃ§Ã£o `fingers_raised()`: identifica quais dedos estÃ£o levantados (Ã­ndice, mÃ©dio, anelar, mÃ­nimo)
- VisualizaÃ§Ã£o em tempo real com desenho dos landmarks
- DependÃªncias jÃ¡ instaladas: `mediapipe==0.10.21`, `opencv-python==4.12.0.88`, `sounddevice==0.5.2`

### ğŸ”¨ PrÃ³ximos Passos:

### ğŸ§© 1. Aprimorar Controle por Gestos
- **Refatorar `fingers_raised()`** para incluir detecÃ§Ã£o do polegar
- **Criar mÃ³dulo `gesture_recognition.py`** com classe para reconhecer gestos compostos:
  - âœ‹ **MÃ£o aberta** (todos os 5 dedos levantados) â†’ ativa o assistente
  - â˜ï¸ **Um dedo levantado** (apenas indicador) â†’ inicia gravaÃ§Ã£o de voz
  - ğŸ‘Š **Punho fechado** (nenhum dedo levantado) â†’ encerra o diÃ¡logo
  - âœŒï¸ **Dois dedos** (indicador + mÃ©dio) â†’ cancela operaÃ§Ã£o atual
- **Implementar mÃ¡quina de estados** para gerenciar transiÃ§Ãµes entre gestos
- Exibir feedback visual na tela usando `cv2.putText()` ("Assistente ativado", "Escutando...", etc.)
- Corrigir bug do parÃ¢metro `side_inverted` nÃ£o utilizado no loop principal

---

### ğŸ™ï¸ 2. Implementar Reconhecimento de Voz Local (Whisper)
- **Criar mÃ³dulo `voice_recognition.py`** com classe `VoiceRecorder`:
  - Integrar o **modelo openai-whisper**, rodando **localmente** (sem API nem custo)
  - Usar `sounddevice` (jÃ¡ instalado) para captura de Ã¡udio do microfone

- **Fluxo de gravaÃ§Ã£o**:
  1. Ao detectar o gesto â˜ï¸ (um dedo), iniciar gravaÃ§Ã£o de Ã¡udio (5-10 segundos)
  2. Salvar temporariamente como `temp/comando.wav`
  3. Transcrever o Ã¡udio para texto em portuguÃªs com Whisper:
     ```python
     import whisper
     model = whisper.load_model("base")  # ou "small" para melhor precisÃ£o
     result = model.transcribe("temp/comando.wav", language="pt")
     texto_transcrito = result["text"]
     ```
  4. Retornar texto transcrito para processamento pela IA

- **Implementar feedback visual** durante gravaÃ§Ã£o (Ã­cone de microfone, contador de tempo)

**Bibliotecas adicionais necessÃ¡rias:**
```bash
pip install openai-whisper
